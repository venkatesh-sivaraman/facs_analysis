{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FACS Analysis\n",
    "\n",
    "This Jupyter notebook walks you through the basic steps of analyzing Mass-Titr FACS results. For high-throughput binding experiments, the `highThroughputScripts` pipeline is available on [GitHub](https://github.com/KeatingLab/highThroughputScripts/tree/vs_optimization).\n",
    "\n",
    "To complete the analysis, run all cells in order one-by-one unless otherwise specified, filling in or changing input values as needed. To export a plot, you may want to change the DPI in the `plt.figure` command, i.e. `plt.figure(..., dpi=160)`.\n",
    "\n",
    "**Requirements**: This notebook requires Python 2, and the following modules:\n",
    "\n",
    "* `FlowCytometryTools` (install using `pip install flowcytometrytools`)\n",
    "* `lmfit`\n",
    "* `ipywidgets`, version 7.2 or later (upgrade if necessary)\n",
    "* The script `facs_utils.py` must be in the same directory as this notebook.\n",
    "\n",
    "After installing these modules, be sure to restart the notebook kernel to make sure the modules are available.\n",
    "\n",
    "*Written by*: Venkatesh Sivaraman, February 2019, adapted from scripts by Dustin Whitney and Theresa Hwang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Experiment metadata\n",
    "# Name:\n",
    "# Date:\n",
    "# Info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline\n",
    "import os\n",
    "from FlowCytometryTools import FCMeasurement\n",
    "from FlowCytometryTools import ThresholdGate, PolyGate\n",
    "import pandas as pd \n",
    "from lmfit import Model, Parameters, Minimizer\n",
    "from facs_utils import *\n",
    "from collections import OrderedDict\n",
    "from FlowCytometryTools.core.transforms import hlog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary that contains gating information (rerun this cell to reset interactive gate info)\n",
    "GATE_RESULTS = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0. Preliminaries\n",
    "\n",
    "Change the values below as appropriate for your experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to directory containing .fcs files\n",
    "DATA_PATH = \"\"\n",
    "\n",
    "# Number of specimens\n",
    "NUM_SPECIMENS = 1\n",
    "\n",
    "# Letter codes used\n",
    "LETTER_CODES = 'ABCDEFGH'\n",
    "\n",
    "# Number of samples per letter code\n",
    "NUM_PER_LETTER = 12\n",
    "\n",
    "HYPERLOG_B = 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining axes for various types of gates\n",
    "scatter_axes = [\"FSC-H\", \"SSC-H\"]\n",
    "fluor_axes = [\"Alexa Fluor 680-A\", \"PE-A\"]\n",
    "\n",
    "# These axes can be hyperlog-transformed if specified\n",
    "transformable_axes = [\"FSC-H\", \"SSC-H\", \"SSC-W\", \"Alexa Fluor 680-A\", \"PE-A\"]\n",
    "\n",
    "# Expression axis\n",
    "expression_axis = \"PE-A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions to get sample paths and data\n",
    "\n",
    "def specimen_files(specimen_number, letter=None):\n",
    "    \"\"\"Returns the list of fcs files in DATA_PATH corresponding to the given (integer) specimen number. If \n",
    "    letter is not None, also looks for specimens with the given letter code.\"\"\"\n",
    "    prefix = 'Specimen_' + str(specimen_number).zfill(3)\n",
    "    \n",
    "    def matches(name):\n",
    "        if not name.startswith(prefix): return False\n",
    "        if letter is not None and (\"_\" + letter) not in name: return False\n",
    "        return True\n",
    "    \n",
    "    paths = [os.path.join(DATA_PATH, path) for path in os.listdir(DATA_PATH) if matches(path)]\n",
    "    return sorted(paths, key=lambda path: path[path.find(\".fcs\") - 3:])\n",
    "\n",
    "def get_sample_path(specimen_number, letter, sample_number):\n",
    "    \"\"\"Gets the path for the sample with the given specimen number, letter code, and sample number for the letter code.\"\"\"\n",
    "    prefix = 'Specimen_' + str(specimen_number).zfill(3) + '_' + letter + str(sample_number) + '_'\n",
    "    \n",
    "    paths = [os.path.join(DATA_PATH, path) for path in os.listdir(DATA_PATH) if path.startswith(prefix)]\n",
    "    assert len(paths) == 1, \"Multiple paths satisfy sample path condition\"\n",
    "    return paths[0]\n",
    "\n",
    "def transform_sample(sample):\n",
    "    \"\"\"Performs the standard hyperlog transformation on the given sample.\"\"\"\n",
    "    return sample.transform('hlog', channels=transformable_axes, b=HYPERLOG_B)\n",
    "    \n",
    "def get_sample(path, id_name, transform=False):\n",
    "    \"\"\"Gets a measurement from the given fcs file path, transforming its scatter values using a hyperlog \n",
    "    transformation if specified.\"\"\"\n",
    "    sample = FCMeasurement(ID=id_name, datafile=path)\n",
    "    if transform:\n",
    "        return transform_sample(sample)\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Forward-Scatter and Side-Scatter Gating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sample files to test the scatter gates on\n",
    "\n",
    "test_files = specimen_files(1, letter='A')\n",
    "test_samples = [get_sample(path, \"Test\", transform=True) for path in test_files]\n",
    "\n",
    "test_file = test_files[0]\n",
    "test_sample = test_samples[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: The following cell opens the interactive gate drawing tool. If no polygon gate is desired, skip this cell, and in the subsequent cell set `scatter_gate` to `None` before running. Alternatively, if you already know the vertices for the polygon you want, skip this cell and replace `GATE_RESULTS['scatter_gate']` in the first line with the list of coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the number of vertices to use on the gate.\n",
    "num_points = 3\n",
    "\n",
    "# Opens the interactive gate drawing tool.\n",
    "# Use test_samples to plot all 'A' samples together, or test_sample to plot just the first sample (may be faster).\n",
    "vertex_control(test_samples, scatter_axes, num_points, GATE_RESULTS, 'scatter_gate', log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the main scatter gate using the interactive results. Set scatter_gate to None if no polygon gate is desired.\n",
    "gate_vertices = GATE_RESULTS['scatter_gate']\n",
    "scatter_gate = PolyGate(gate_vertices, scatter_axes, region='in', name='scatter_gate')\n",
    "print \"Gate created with vertices:\", [tuple(row) for row in gate_vertices]\n",
    "\n",
    "# Create some threshold gates to further filter the data.\n",
    "scatter_threshold_gates = [\n",
    "    # ThresholdGate(0, 'FSC-H', region='above'),\n",
    "    # ThresholdGate(9000, 'SSC-H', region='below'),\n",
    "    # ThresholdGate(300, 'SSC-H', region='above')\n",
    "]\n",
    "\n",
    "def gate_by_scatter(sample):\n",
    "    \"\"\"Gates the given FCMeasurement using the scatter_gate and the list of scatter_threshold_gates. \n",
    "    Returns the new gated sample.\"\"\"\n",
    "    tsample = sample\n",
    "    if scatter_gate is not None:\n",
    "        tsample = tsample.gate(scatter_gate)\n",
    "    for gate in scatter_threshold_gates:\n",
    "        tsample = tsample.gate(gate)\n",
    "    return tsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show several examples with this gate\n",
    "files = specimen_files(1, letter='A')\n",
    "gates_to_show = ([scatter_gate] if scatter_gate is not None else []) + scatter_threshold_gates\n",
    "plt.figure(figsize=(16, 10))\n",
    "\n",
    "for i, path in enumerate(files[:24]):\n",
    "    plt.subplot(4, 6, i + 1)\n",
    "    \n",
    "    # Get the sample, gate it, and plot it\n",
    "    sample = get_sample(path, \"Sample {}\".format(i), transform=True)\n",
    "    filtered_sample = gate_by_scatter(sample)\n",
    "    filtered_sample.plot(scatter_axes, ax=plt.gca(), kind='scatter', color='r', s=1, gates=gates_to_show)\n",
    "    \n",
    "    plt.title(os.path.splitext(os.path.basename(path))[0])\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Fluorescence Gating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gate the test samples from above\n",
    "fluor_samples = [gate_by_scatter(samp) for samp in test_samples]\n",
    "fluor_sample = fluor_samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the first sample, and all the samples\n",
    "plt.figure()\n",
    "fluor_sample.plot(fluor_axes, ax=plt.gca(), kind='scatter', color='r', s=1);\n",
    "plt.figure()\n",
    "for sample in fluor_samples:\n",
    "    sample.plot(fluor_axes, ax=plt.gca(), kind='scatter', color='r', s=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: The following cell opens the interactive gate drawing tool. If no polygon gate is desired, skip this cell, and in the subsequent cell set `fluor_gate` to `None` before running. Alternatively, if you already know the vertices for the polygon you want, skip this cell and replace `GATE_RESULTS['fluor_gate']` in the first line with the list of coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the number of vertices to use on the gate.\n",
    "num_points = 3\n",
    "\n",
    "# Use fluor_samples to plot all 'A' samples together, or fluor_sample to plot just the first sample (may be faster).\n",
    "vertex_control(fluor_samples, fluor_axes, num_points, GATE_RESULTS, 'fluor_gate', log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the main polygon fluorescence gate using the interactive results. \n",
    "# Set fluor_gate to None if no polygon gate is desired.\n",
    "gate_vertices = GATE_RESULTS['fluor_gate']\n",
    "fluor_gate = PolyGate(gate_vertices, fluor_axes, region='in', name='fluor_gate')\n",
    "print \"Gate created with vertices:\", [tuple(row) for row in gate_vertices]\n",
    "\n",
    "\n",
    "# Create some threshold gates to further filter the data.\n",
    "fluor_threshold_gates = [\n",
    "    # ThresholdGate(1, 'PE-A', region = 'above'),\n",
    "    # ThresholdGate(4000, 'Alexa Fluor 680-A', region = 'above'),\n",
    "]\n",
    "\n",
    "def gate_by_fluorescence(sample):\n",
    "    \"\"\"Gates the given FCMeasurement using the fluor_gate and the list of fluor_threshold_gates. \n",
    "    Returns the new gated sample.\"\"\"\n",
    "    tsample = sample\n",
    "    if fluor_gate is not None:\n",
    "        tsample = sample.gate(fluor_gate)\n",
    "    for gate in fluor_threshold_gates:\n",
    "        tsample = tsample.gate(gate)\n",
    "    return tsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show several examples with all gates applied\n",
    "files = specimen_files(1, letter='A')\n",
    "gates_to_show = ([fluor_gate] if fluor_gate is not None else []) + fluor_threshold_gates\n",
    "plt.figure(figsize=(16, 10))\n",
    "\n",
    "for i, path in enumerate(files[:24]):\n",
    "    plt.subplot(4, 6, i + 1)\n",
    "    \n",
    "    # Get the sample, gate it, and plot it\n",
    "    sample = get_sample(path, \"Sample {}\".format(i), transform=True)\n",
    "    filtered_sample = gate_by_fluorescence(gate_by_scatter(sample))\n",
    "    filtered_sample.plot(fluor_axes, ax=plt.gca(), kind='scatter', color='r', s=1, gates=gates_to_show)\n",
    "    \n",
    "    plt.title(os.path.splitext(os.path.basename(path))[0])\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. $K_d$ Estimation\n",
    "\n",
    "Up until now we have only been working with a small subset of the data - now, we will perform the analysis on all samples. \n",
    "\n",
    "**A note on transformations:** All of the gates we have created are in hyperlog-space, so this script is careful to apply any gates in that space. The best practice for fitting, however, is usually to perform the fit on linear (un-transformed) medians. If the `linear_medians` variable below is set to `True`, the median of the un-transformed data will be used (still gated in log space); otherwise, the median of the transformed data will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If this is set to True, we will use the untransformed data to get the medians; \n",
    "# otherwise, we use the log-transformed data\n",
    "linear_medians = True\n",
    "\n",
    "# Get the medians of every gated sample\n",
    "medians = np.zeros((NUM_SPECIMENS, len(LETTER_CODES), NUM_PER_LETTER))\n",
    "\n",
    "for specimen in range(1, NUM_SPECIMENS + 1):\n",
    "    for letter_idx, letter in enumerate(LETTER_CODES):\n",
    "        for sample_num in range(1, NUM_PER_LETTER + 1):\n",
    "            # Get the path for this sample\n",
    "            path = get_sample_path(specimen, letter, sample_num)\n",
    "            id_name = os.path.splitext(os.path.basename(path))[0]\n",
    "            \n",
    "            # Load the sample and gate it\n",
    "            sample = get_sample(path, id_name, transform=False)\n",
    "            tsample = transform_sample(sample)\n",
    "            filtered_tsample = gate_by_fluorescence(gate_by_scatter(tsample))\n",
    "            filtered_sample_data = sample.get_data().loc[filtered_tsample.get_data().index]\n",
    "            \n",
    "            # Compute median of expression axis values\n",
    "            if linear_medians:\n",
    "                medians[specimen - 1, letter_idx, sample_num - 1] = filtered_sample_data[expression_axis].median()\n",
    "            else:\n",
    "                medians[specimen - 1, letter_idx, sample_num - 1] = filtered_tsample.data[expression_axis].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the medians\n",
    "specimen_to_plot = 1\n",
    "letter_to_plot = 'C'\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "for sample_num in range(1, NUM_PER_LETTER + 1):\n",
    "    # Get the path for this sample\n",
    "    path = get_sample_path(specimen_to_plot, letter_to_plot, sample_num)\n",
    "    id_name = os.path.splitext(os.path.basename(path))[0]\n",
    "    median = medians[specimen_to_plot - 1, LETTER_CODES.find(letter_to_plot), sample_num - 1]\n",
    "\n",
    "    # Load the sample and gate it\n",
    "    sample = get_sample(path, id_name, transform=True)\n",
    "    filtered_sample = gate_by_fluorescence(gate_by_scatter(sample))\n",
    "    \n",
    "    # Plot\n",
    "    plt.subplot(2, int(ceil(NUM_PER_LETTER / 2.0)), sample_num)\n",
    "    filtered_sample.plot(fluor_axes, ax=plt.gca(), kind='scatter', color='r', s=1)\n",
    "    # The median should be hlog-transformed for display if it's on a linear scale\n",
    "    plt.hlines(hlog(median, b=HYPERLOG_B) if linear_medians else median, *plt.xlim(), color='b')\n",
    "    plt.title(id_name)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define your concentrations here, in the order that they would appear in the below mapping.\n",
    "concentrations = np.array([20, 5, 1.25, .312, 0.08, 0.01])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a mapping that tells us which letter codes and indexes belong to the same titration. The default behavior, implemented below, is to reshape the matrix to `(NUM_SPECIMENS, x, len(concentrations))`, where `x` is the number of rows needed to use up all 96 values per specimen. For example, with 6 concentrations, the first titration will consist of samples A1 through A6; the second will consist of A7 through A12; the third B1 through B6; and so on. \n",
    "\n",
    "If your plate is organized differently, you'll likely need to implement a different behavior to create `median_matrix` such that its first dimension is the number of specimens and its third dimension is equal to the number of concentrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals_per_specimen = medians.shape[1] * medians.shape[2]\n",
    "assert vals_per_specimen / len(concentrations) == round(vals_per_specimen / float(len(concentrations))), \"Number of concentrations does not divide the total number of samples evenly. Please implement a different mapping method to obtain the median fluorescence matrix.\"\n",
    "median_matrix = medians.reshape(NUM_SPECIMENS, -1, len(concentrations))\n",
    "\n",
    "print \"Median matrix: \", median_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give each set of samples a more descriptive label for bookkeeping\n",
    "labels = [\"Sample 1\", \"Sample 2\", \"Sample 3\", \"Sample 4\",\n",
    "         \"Sample 5\", \"Sample 6\", \"Sample 7\", \"Sample 8\",\n",
    "         \"Sample 9\", \"Sample 10\", \"Sample 11\", \"Sample 12\",\n",
    "         \"Sample 13\", \"Sample 14\", \"Sample 15\", \"Sample 16\"]\n",
    "\n",
    "assert len(labels) == median_matrix.shape[0] * median_matrix.shape[1], \"Need {} total labels, got {}\".format(median_matrix.shape[0] * median_matrix.shape[1], len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we compute all the Kds. \n",
    "# Initial parameters:\n",
    "init_lower = 0\n",
    "init_upper = 4000\n",
    "init_kd = 1\n",
    "plot_fits = True\n",
    "\n",
    "# List of dictionaries of fit results\n",
    "fit_results = []\n",
    "\n",
    "label_index = 0\n",
    "    \n",
    "for specimen in range(median_matrix.shape[0]):\n",
    "    \n",
    "    if plot_fits: plt.figure(figsize=(16, 16))\n",
    "    for i, dataset in enumerate(median_matrix[specimen]):\n",
    "        \n",
    "        if plot_fits:\n",
    "            plt.subplot(int(ceil(median_matrix.shape[1] / 4.0)), 4, i + 1)\n",
    "        \n",
    "        # Compute fit and save to results dictionary\n",
    "        kd, sat, init, err, chisqr, r2 = run_lmfit(concentrations, dataset, init_lower, init_upper, init_kd, plot_fits)\n",
    "        result = [(\"label\", labels[label_index]), \n",
    "                  (\"kd\", kd), (\"sat\", sat), (\"init\", init),\n",
    "                  (\"err\", err), (\"chisqr\", chisqr), (\"r2\", r2)]\n",
    "        for conc, val in zip(concentrations, dataset):\n",
    "            result.append((\"conc_{}\".format(conc), val))\n",
    "        fit_results.append(OrderedDict(result))\n",
    "        label_index += 1\n",
    "        \n",
    "        if plot_fits:\n",
    "            plt.title(\"Titration {} (Kd = {:.3g})\".format(i + 1, kd))\n",
    "            \n",
    "    if plot_fits:\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a dataframe from the results list\n",
    "results_df = pd.DataFrame(fit_results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose an output path, and write out to CSV\n",
    "out_path = \"kd_list.csv\"\n",
    "results_df.to_csv(out_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all, folks!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python2env",
   "language": "python",
   "name": "python2env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
