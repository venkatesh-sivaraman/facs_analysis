{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FACS Analysis\n",
    "\n",
    "This Jupyter notebook walks you through the basic steps of analyzing Mass-Titr FACS results. For high-throughput binding experiments, the `highThroughputScripts` pipeline is available on [GitHub](https://github.com/KeatingLab/highThroughputScripts/tree/vs_optimization).\n",
    "\n",
    "To complete the analysis, run all cells in order one-by-one unless otherwise specified, filling in or changing input values as needed. (Hint: Use `Shift+Enter` to run a cell then advance to the next one.) To export a plot, you may want to change the DPI in the `plt.figure` command, i.e. `plt.figure(..., dpi=160)`.\n",
    "\n",
    "**Requirements**: This notebook requires Python 2, and the following modules:\n",
    "\n",
    "* `FlowCytometryTools` (install using `pip install flowcytometrytools`)\n",
    "* `lmfit`\n",
    "* `ipywidgets`, version 7.2 or later (upgrade if necessary)\n",
    "* The script `facs_utils.py` must be in the same directory as this notebook.\n",
    "\n",
    "After installing these modules, be sure to restart the notebook kernel to make sure the modules are available.\n",
    "\n",
    "*Written by*: Venkatesh Sivaraman, February 2019, adapted from scripts by Dustin Whitney and Theresa Hwang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Experiment metadata\n",
    "# Name:\n",
    "# Date:\n",
    "# Info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline\n",
    "import os\n",
    "from FlowCytometryTools import FCMeasurement\n",
    "from FlowCytometryTools import ThresholdGate, PolyGate\n",
    "import pandas as pd \n",
    "from lmfit import Model, Parameters, Minimizer\n",
    "from facs_utils import *\n",
    "from collections import OrderedDict\n",
    "from FlowCytometryTools.core.transforms import hlog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary that contains gating information (rerun this cell to reset interactive gate info)\n",
    "GATE_RESULTS = {}\n",
    "\n",
    "# Boundary value for hyperlog transformation\n",
    "HYPERLOG_B = 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0. Preliminaries\n",
    "\n",
    "First we need to provide some information about the experiment, and point the script to where the data is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to directory containing .fcs files\n",
    "DATA_PATH = \"../FACS_data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define and label your titrations here, along with the concentrations at which the experiment was performed. \n",
    "\n",
    "Because there are many different methods of plate organization and file naming, you must use the `make_titration` function to tell the script which fcs files to draw data from for each titration. The function takes as parameters the **specimen number**, the **letter code**, and the **number code** for each stop. Each parameter can also be a list, range, or string whose length is the number of concentrations. *Remember that the `range` function's upper bound is non-inclusive, so `range(1, 13)` produces the values [1,2,...,12].*\n",
    "\n",
    "**Examples:**\n",
    "* For the command `make_titration(1, 'ABCDEFGH', 1)`, the following wells from Specimen 1 will be used: A1, B1, C1, D1, E1, F1, G1, H1.\n",
    "* For the command `make_titration(2, 'B', range(1, 7)`, wells B1-B6 prefixed with Specimen 2 will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCENTRATIONS = np.array([20, 5, 1.25, .312, 0.08, 0.01])\n",
    "\n",
    "TITRATIONS = [\n",
    "    # The behavior implemented here is to divide each letter code into two sets (1-6 and 7-12),\n",
    "    # each of which constitutes one titration. Adjust this as needed based on your \n",
    "    # experimental setup.\n",
    "    make_titration(1, 'A', range(1, 7)),\n",
    "    make_titration(1, 'A', range(7, 13)),\n",
    "    make_titration(1, 'B', range(1, 7)),\n",
    "    make_titration(1, 'B', range(7, 13)),\n",
    "    make_titration(1, 'C', range(1, 7)),\n",
    "    make_titration(1, 'C', range(7, 13)),\n",
    "    make_titration(1, 'D', range(1, 7)),\n",
    "    make_titration(1, 'D', range(7, 13)),\n",
    "    make_titration(1, 'E', range(1, 7)),\n",
    "    make_titration(1, 'E', range(7, 13)),\n",
    "    make_titration(1, 'F', range(1, 7)),\n",
    "    make_titration(1, 'F', range(7, 13)),\n",
    "    make_titration(1, 'G', range(1, 7)),\n",
    "    make_titration(1, 'G', range(7, 13)),\n",
    "    make_titration(1, 'H', range(1, 7)),\n",
    "    make_titration(1, 'H', range(7, 13))\n",
    "]\n",
    "\n",
    "# Add a descriptive label here for each titration you listed above (e.g. indicate the peptide being tested).\n",
    "LABELS = [\n",
    "    \"Sample 1\", \"Sample 2\", \"Sample 3\", \"Sample 4\",\n",
    "    \"Sample 5\", \"Sample 6\", \"Sample 7\", \"Sample 8\",\n",
    "    \"Sample 9\", \"Sample 10\", \"Sample 11\", \"Sample 12\",\n",
    "    \"Sample 13\", \"Sample 14\", \"Sample 15\", \"Sample 16\"\n",
    "]\n",
    "\n",
    "assert all([len(t) == len(CONCENTRATIONS) for t in TITRATIONS]), \"All titrations must have same number of concentrations as CONCENTRATIONS list\"\n",
    "assert len(LABELS) == len(TITRATIONS), \"Need {} labels to match titrations list, found {}\".format(len(TITRATIONS), len(LABELS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining axes for various types of gates\n",
    "scatter_axes_1 = [\"FSC-H\", \"SSC-H\"]\n",
    "scatter_axes_2 = [\"SSC-H\", \"SSC-W\"]\n",
    "fluor_axes = [\"Alexa Fluor 680-A\", \"PE-A\"]\n",
    "\n",
    "# These axes can be hyperlog-transformed if specified\n",
    "transformable_axes = [\"FSC-H\", \"SSC-H\", \"SSC-W\", \"Alexa Fluor 680-A\", \"PE-A\"]\n",
    "\n",
    "# Expression axis\n",
    "expression_axis = \"PE-A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions to get sample paths and data\n",
    "\n",
    "def get_titration_files(titration):\n",
    "    \"\"\"Returns the list of fcs files in DATA_PATH corresponding to the given list of concentration stops.\"\"\"\n",
    "    return [get_sample_path(*stop) for stop in titration]\n",
    "\n",
    "def get_sample_path(specimen_number, letter, sample_number):\n",
    "    \"\"\"Gets the path for the sample with the given specimen number, letter code, and sample number for the letter code.\"\"\"\n",
    "    prefix = 'Specimen_' + str(specimen_number).zfill(3) + '_' + letter + str(sample_number) + '_'\n",
    "    \n",
    "    paths = [os.path.join(DATA_PATH, path) for path in os.listdir(DATA_PATH) if path.startswith(prefix)]\n",
    "    assert len(paths) > 0, \"No path found for ({}, {}, {})\".format(specimen_number, letter, sample_number)\n",
    "    assert len(paths) == 1, \"Multiple paths satisfy sample path condition\"\n",
    "    return paths[0]\n",
    "\n",
    "def transform_sample(sample):\n",
    "    \"\"\"Performs the standard hyperlog transformation on the given sample.\"\"\"\n",
    "    return sample.transform('hlog', channels=transformable_axes, b=HYPERLOG_B)\n",
    "    \n",
    "def get_sample(path, id_name, transform=False):\n",
    "    \"\"\"Gets a measurement from the given fcs file path, transforming its scatter values using a hyperlog \n",
    "    transformation if specified.\"\"\"\n",
    "    sample = FCMeasurement(ID=id_name, datafile=path)\n",
    "    if transform:\n",
    "        return transform_sample(sample)\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Forward-Scatter and Side-Scatter Gating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sample files to test the scatter gates on\n",
    "\n",
    "test_files = get_titration_files(TITRATIONS[0])\n",
    "test_samples = [get_sample(path, \"Test\", transform=True) for path in test_files]\n",
    "\n",
    "test_file = test_files[0]\n",
    "test_sample = test_samples[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1(a). Drawing Gates\n",
    "**NOTE**: The following two cells utilize the interactive gate drawing tool, the first to draw a gate on the FSC-H/SSC-H plot, and the second to gate the SSC-H/SSC-W plot. If no polygon gate is desired, simply skip over the cell without running it. Alternatively, if you already know the vertices for the desired gates, skip to section 1(b) and replace the value of either `gate_vertices_1` or `gate_vertices_2` with the list of coordinates you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the number of vertices to use on the gate.\n",
    "num_points = 3\n",
    "\n",
    "# Opens the interactive gate drawing tool.\n",
    "# Use test_samples to plot all 'A' samples together, or test_sample to plot just the first sample (may be faster).\n",
    "vertex_control(test_samples, scatter_axes_1, num_points, GATE_RESULTS, 'scatter_gate_1', log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the number of vertices to use on the second gate.\n",
    "num_points = 4\n",
    "\n",
    "# Opens the interactive gate drawing tool.\n",
    "# Use test_samples to plot all 'A' samples together, or test_sample to plot just the first sample (may be faster).\n",
    "vertex_control(test_samples, scatter_axes_2, num_points, GATE_RESULTS, 'scatter_gate_2', log=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1(b). Defining the Gates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the main scatter gate using the interactive results. Set the gate_vertices variables to None \n",
    "# if no polygon gate is desired.\n",
    "gate_vertices_1 = GATE_RESULTS.get('scatter_gate_1', None)\n",
    "gate_vertices_2 = GATE_RESULTS.get('scatter_gate_2', None)\n",
    "scatter_gates = []\n",
    "\n",
    "if gate_vertices_1 is not None:\n",
    "    scatter_gates.append(PolyGate(gate_vertices_1, scatter_axes_1, region='in', name='scatter_gate_1'))\n",
    "    print(\"Gate 1 created with vertices: {}\".format([tuple(row) for row in gate_vertices_1]))\n",
    "if gate_vertices_2 is not None:\n",
    "    scatter_gates.append(PolyGate(gate_vertices_2, scatter_axes_2, region='in', name='scatter_gate_2'))\n",
    "    print(\"Gate 2 created with vertices: {}\".format([tuple(row) for row in gate_vertices_2]))\n",
    "    \n",
    "if gate_vertices_1 is None and gate_vertices_2 is None:\n",
    "    print(\"No polygon gates will be used.\")\n",
    "\n",
    "# Optionally, create some threshold gates to further filter the data.\n",
    "scatter_threshold_gates = [\n",
    "    # ThresholdGate(0, 'FSC-H', region='above'),\n",
    "    # ThresholdGate(9000, 'SSC-H', region='below'),\n",
    "    # ThresholdGate(300, 'SSC-H', region='above')\n",
    "]\n",
    "\n",
    "def gate_by_scatter(sample):\n",
    "    \"\"\"Gates the given FCMeasurement using the scatter_gate and the list of scatter_threshold_gates. \n",
    "    Returns the new gated sample.\"\"\"\n",
    "    tsample = sample\n",
    "    for gate in scatter_gates + scatter_threshold_gates:\n",
    "        tsample = tsample.gate(gate)\n",
    "    return tsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show several examples from the first titration with this gate\n",
    "files = get_titration_files(TITRATIONS[0])\n",
    "gates_to_show = [x for x in scatter_gates + scatter_threshold_gates if all([c in scatter_axes for c in x.channels])]\n",
    "plt.figure(figsize=(16, 10))\n",
    "\n",
    "for i, path in enumerate(files[:24]):\n",
    "    plt.subplot(4, 6, i + 1)\n",
    "    \n",
    "    # Get the sample, gate it, and plot it\n",
    "    sample = get_sample(path, \"Sample {}\".format(i), transform=True)\n",
    "    filtered_sample = gate_by_scatter(sample)\n",
    "    filtered_sample.plot(scatter_axes, ax=plt.gca(), kind='scatter', color='r', s=1, gates=gates_to_show)\n",
    "    \n",
    "    plt.title(os.path.splitext(os.path.basename(path))[0])\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Fluorescence Gating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gate the test samples from above\n",
    "fluor_samples = [gate_by_scatter(samp) for samp in test_samples]\n",
    "fluor_sample = fluor_samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the first sample, and all the samples\n",
    "plt.figure()\n",
    "fluor_sample.plot(fluor_axes, ax=plt.gca(), kind='scatter', color='r', s=1);\n",
    "plt.figure()\n",
    "for sample in fluor_samples:\n",
    "    sample.plot(fluor_axes, ax=plt.gca(), kind='scatter', color='r', s=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2(a). Drawing Gates\n",
    "\n",
    "The following cell opens the interactive gate drawing tool for the binding and expression axes. If no polygon gate is desired, simply skip to section 2(b). Alternatively, if you already know the vertices for the polygon you want, skip to section 2(b) and replace the value of `gate_vertices` with the list of coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the number of vertices to use on the gate.\n",
    "num_points = 3\n",
    "\n",
    "# Use fluor_samples to plot all 'A' samples together, or fluor_sample to plot just the first sample (may be faster).\n",
    "vertex_control(fluor_samples, fluor_axes, num_points, GATE_RESULTS, 'fluor_gate', log=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2(b). Defining the Gates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the main polygon fluorescence gate using the interactive results. \n",
    "# Set gate_vertices to None if no polygon gate is desired.\n",
    "gate_vertices = GATE_RESULTS.get('fluor_gate', None)\n",
    "\n",
    "if gate_vertices is not None:\n",
    "    fluor_gate = PolyGate(gate_vertices, fluor_axes, region='in', name='fluor_gate')\n",
    "    print(\"Gate created with vertices: {}\".format([tuple(row) for row in gate_vertices]))\n",
    "else:\n",
    "    fluor_gate = None\n",
    "    print(\"No polygon gate will be used.\")\n",
    "\n",
    "\n",
    "# Create some threshold gates to further filter the data.\n",
    "fluor_threshold_gates = [\n",
    "    # ThresholdGate(1, 'PE-A', region = 'above'),\n",
    "    # ThresholdGate(4000, 'Alexa Fluor 680-A', region = 'above'),\n",
    "]\n",
    "\n",
    "def gate_by_fluorescence(sample):\n",
    "    \"\"\"Gates the given FCMeasurement using the fluor_gate and the list of fluor_threshold_gates. \n",
    "    Returns the new gated sample.\"\"\"\n",
    "    tsample = sample\n",
    "    if fluor_gate is not None:\n",
    "        tsample = sample.gate(fluor_gate)\n",
    "    for gate in fluor_threshold_gates:\n",
    "        tsample = tsample.gate(gate)\n",
    "    return tsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show several examples from the first titration with all gates applied\n",
    "files = get_titration_files(TITRATIONS[0])\n",
    "gates_to_show = ([fluor_gate] if fluor_gate is not None else []) + fluor_threshold_gates\n",
    "plt.figure(figsize=(16, 10))\n",
    "\n",
    "for i, path in enumerate(files[:24]):\n",
    "    plt.subplot(4, 6, i + 1)\n",
    "    \n",
    "    # Get the sample, gate it, and plot it\n",
    "    sample = get_sample(path, \"Sample {}\".format(i), transform=True)\n",
    "    filtered_sample = gate_by_fluorescence(gate_by_scatter(sample))\n",
    "    filtered_sample.plot(fluor_axes, ax=plt.gca(), kind='scatter', color='r', s=1, gates=gates_to_show)\n",
    "    \n",
    "    plt.title(os.path.splitext(os.path.basename(path))[0])\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. $K_d$ Estimation\n",
    "\n",
    "Up until now we have only been working with a small subset of the data - now, we will perform the analysis on all samples. \n",
    "\n",
    "**A note on transformations:** All of the gates we have created are in hyperlog-space, so this script is careful to apply any gates in that space. The best practice for fitting, however, is usually to perform the fit on linear (un-transformed) medians. If the `linear_medians` variable below is set to `True`, the median of the un-transformed data will be used (still gated in log space); otherwise, the median of the transformed data will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If this is set to True, we will use the untransformed data to get the medians; \n",
    "# otherwise, we use the log-transformed data\n",
    "linear_medians = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the medians of every gated sample\n",
    "medians = np.zeros((len(TITRATIONS), len(CONCENTRATIONS)))\n",
    "\n",
    "for i, titration in enumerate(TITRATIONS):\n",
    "    for j, sample_info in enumerate(titration):\n",
    "        # Get the path for this sample\n",
    "        path = get_sample_path(*sample_info)\n",
    "        id_name = os.path.splitext(os.path.basename(path))[0]\n",
    "\n",
    "        # Load the sample and gate it\n",
    "        sample = get_sample(path, id_name, transform=False)\n",
    "        tsample = transform_sample(sample)\n",
    "        filtered_tsample = gate_by_fluorescence(gate_by_scatter(tsample))\n",
    "        filtered_sample_data = sample.get_data().loc[filtered_tsample.get_data().index]\n",
    "\n",
    "        # Compute median of expression axis values\n",
    "        if linear_medians:\n",
    "            medians[i, j] = filtered_sample_data[expression_axis].median()\n",
    "        else:\n",
    "            medians[i, j] = filtered_tsample.data[expression_axis].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the medians - pick a random titration to look at\n",
    "titration_to_plot = 0\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "for sample_num, sample_info in enumerate(TITRATIONS[titration_to_plot]):\n",
    "    # Get the path for this sample\n",
    "    path = get_sample_path(*sample_info)\n",
    "    id_name = os.path.splitext(os.path.basename(path))[0]\n",
    "    median = medians[titration_to_plot, sample_num]\n",
    "\n",
    "    # Load the sample and gate it\n",
    "    sample = get_sample(path, id_name, transform=True)\n",
    "    filtered_sample = gate_by_fluorescence(gate_by_scatter(sample))\n",
    "    \n",
    "    # Plot\n",
    "    plt.subplot(2, int(ceil(len(CONCENTRATIONS) / 2.0)), sample_num + 1)\n",
    "    filtered_sample.plot(fluor_axes, ax=plt.gca(), kind='scatter', color='r', s=1)\n",
    "    # The median should be hlog-transformed for display if it's on a linear scale\n",
    "    plt.hlines(hlog(median, b=HYPERLOG_B) if linear_medians else median, *plt.xlim(), color='b')\n",
    "    plt.title(id_name)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we compute all the Kds. \n",
    "# Initial parameters:\n",
    "init_lower = 0\n",
    "init_upper = 4000\n",
    "init_kd = 1\n",
    "plot_fits = True\n",
    "\n",
    "# List of dictionaries of fit results\n",
    "fit_results = []\n",
    "\n",
    "if plot_fits: plt.figure(figsize=(16, 16))\n",
    "for i, (label, titration, dataset) in enumerate(zip(LABELS, TITRATIONS, medians)):\n",
    "\n",
    "    if plot_fits:\n",
    "        plt.subplot(int(ceil(len(TITRATIONS) / 4.0)), 4, i + 1)\n",
    "\n",
    "    # Compute fit and save to results dictionary\n",
    "    kd, sat, init, err, chisqr, r2 = run_lmfit(CONCENTRATIONS, dataset, init_lower, init_upper, init_kd, plot_fits)\n",
    "    result = [(\"label\", label), \n",
    "              (\"kd\", kd), (\"sat\", sat), (\"init\", init),\n",
    "              (\"err\", err), (\"chisqr\", chisqr), (\"r2\", r2)]\n",
    "    for conc, val in zip(CONCENTRATIONS, dataset):\n",
    "        result.append((\"conc_{}\".format(conc), val))\n",
    "    fit_results.append(OrderedDict(result))\n",
    "\n",
    "    if plot_fits:\n",
    "        plt.title(\"{} (Kd = {:.3g})\".format(label, kd))\n",
    "            \n",
    "if plot_fits:\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a dataframe from the results list\n",
    "results_df = pd.DataFrame(fit_results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose an output path, and write out to CSV\n",
    "out_path = \"kd_list.csv\"\n",
    "results_df.to_csv(out_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all, folks!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python2env",
   "language": "python",
   "name": "python2env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
